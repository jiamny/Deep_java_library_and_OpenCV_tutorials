package com.jiamny.ML.C03_DecisionTree;

import ai.djl.Device;
import ai.djl.ndarray.NDArray;
import ai.djl.ndarray.NDManager;
import ai.djl.ndarray.types.DataType;
import ai.djl.ndarray.types.Shape;

import java.io.BufferedReader;
import java.io.File;
import java.io.FileInputStream;
import java.io.InputStreamReader;
import java.util.*;

import static com.jiamny.Utils.HelperFunctions.printVectorElements;
import static com.jiamny.Utils.UtilFunctions.train_test_split;

class Node {
    public double gini, threshold;
    public int num_samples, feature_index;
    public NDArray num_samples_per_class, predicted_class;
    Node left, right;

    public Node(double gini, int num_samples, NDArray num_samples_per_class, NDArray predicted_class) {
        this.gini = gini;
        this.num_samples = num_samples;
        this.num_samples_per_class = num_samples_per_class;
        this.predicted_class = predicted_class;
        this.feature_index = 0;
        this.threshold = 0;
        this.left = null;
        this.right = null;
    }
}

class DecisionTree_CART {
    public int max_depth, n_classes_, n_features_;
    public Node tree_;

    public DecisionTree_CART(int max_depth) {
        this.max_depth = max_depth;
    }

    /*
     *Build decision tree classifier
     *         @argument X: Input Tensor
     *         @argument y: ground truth Tensor
     *         @variable n_classes_: Number of Classes in target variable
     *         @variable n_features_: Number of features
     *         @variable tree_: Making decision tree based on X, y along with max_depth
     */
    public void fit(NDArray X, NDArray y) {
        n_classes_ = y.unique().size();  // classes are assumed to go from 0 to n-1
        n_features_ = (int)X.getShape().getShape()[1];
        tree_ = _grow_tree(X, y, 0);
    }

    /*
        Compute Gini impurity of a non-empty node.
        Gini impurity is defined as Σ p(1-p) over all classes, with p the frequency of a
        class within the node. Since Σ p = 1, this is equivalent to 1 - Σ p^2.

        :var m: Sample Size
     */
    public double _gini(NDArray y) {
        long m = y.getShape().getShape()[0];
        double ss = 0;
        //1.0 - sum((torch.sum(y == c).item() // m) ** 2 for c in range(self.n_classes_))
        for(int c = 0; c < n_classes_; c++) {
           ss += Math.pow(Math.floorDiv((y.eq(c)).sum().toLongArray()[0], m), 2);
        }
        return (1.0 - ss);
    }

    /*
    Find the best split for a node.
        "Best" means that the average impurity of the two children, weighted by their
        population, is the smallest possible. Additionally it must be less than the
        impurity of the current node.
        To find the best split, we loop through all the features, and consider all the
        midpoints between adjacent training samples as possible thresholds. We compute
        the Gini impurity of the split generated by that particular feature/threshold
        pair, and return the pair with smallest impurity.
        Returns:
            best_idx: Index of the feature for best split, or None if no split is found.
            best_thr: Threshold to use for the split, or None if no split is found.
     */

    public ArrayList<String> _best_split(NDArray X, NDArray y) {
        ArrayList<String> res = null;
        // Need at least two elements to split a node.
        int m = (int)(y.getShape().getShape()[0]);

        if( m <= 1 ) {
            res = null;
            return res;
        }

        // Count of each class in the current node.
        int [] num_parent = new int[n_classes_]; //[torch.sum(y == c).item() for c in range(self.n_classes_)]
        for(int c = 0; c < n_classes_; c++) {
            num_parent[c] = (int) ((y.eq(c)).sum().toLongArray()[0]);
        }
        System.out.print("num_parent: ");
        printVectorElements(num_parent);

        // Gini of current node.
        //best_gini = 1.0 - sum((n // m) ** 2 for n in num_parent)
        double ss = 0;
        for(int c = 0; c < num_parent.length; c++) {
            ss += Math.pow(Math.floorDiv(num_parent[c], m), 2);
        }
        double best_gini = 1.0 - ss;
        int best_idx = -1;
        double best_thr = -1;

        // Loop through all features.
        for(int idx = 0; idx < n_features_; idx++ ) {
            // Sort data along selected feature.
            //thresholds, classes = zip( * sorted(zip(X[:,idx],y)))
            NDArray _thresholds = X.get("...," + idx);

            // the indices that would sort thresholds NDArray.
            int [] sindex = (_thresholds.argSort()).toType(DataType.INT32, false).toIntArray();

            double [] thresholds = new double[sindex.length];
            int [] classes = new int[sindex.length];
            for( int i = 0; i < sindex.length; i++ ) {
                thresholds[i] = _thresholds.toDoubleArray()[sindex[i]];
                classes[i] = y.toIntArray()[sindex[i]];
            }

            /*
            # We could actually split the node according to each feature/threshold pair
            # and count the resulting population for each class in the children, but
            # instead we compute them in an iterative fashion, making this for loop
            # linear rather than quadratic.
             */
            int [] num_left = new int [n_classes_];
            Arrays.fill(num_left, 0);
            int [] num_right = Arrays.copyOf(num_parent, num_parent.length);

            for(int i = 1; i < m; i++) {  // possible split positions
                int c = classes[i - 1];
                System.out.println("c " + c + " num_left[c] " + num_left[c]);
                num_left[c] += 1;
                num_right[c] -= 1;

                ss = 0;
                for(int x = 0; x < n_classes_; x++) {
                    ss += Math.pow(Math.floorDiv(num_left[x], i), 2);
                }
                double gini_left = 1.0 - ss;

                ss = 0;
                for(int x = 0; x < n_classes_; x++) {
                    ss += Math.pow(Math.floorDiv(num_right[x], (m - i)), 2);
                }
                double gini_right = 1.0 - ss;

                // The Gini impurity of a split is the weighted average of the Gini
                // impurity of the children.
                double gini = 1.0*(i * gini_left + (m - i) * gini_right) / m;

                // The following condition is to make sure we don't try to split two
                // points with identical values for that feature, as it is impossible
                // (both have to end up on the same side of a split).

                if(thresholds[i] == thresholds[i - 1])
                    continue;

                if( gini < best_gini ) {
                    best_gini = gini;
                    best_idx = idx;
                    best_thr = (thresholds[i] +
                            thresholds[i - 1]) / 2.0;  //midpoint
                }
            }
        }
        if( best_idx < 0 && best_thr < 0) {
            res = null;
        } else {
           res = new ArrayList<String>();
           res.add(String.valueOf(best_idx));
           res.add(String.valueOf(best_thr));
        }
        return res;
    }

    // Build a decision tree by recursively finding the best split.
    public Node _grow_tree(NDArray X, NDArray y, int depth) {
        // Population for each class in current node. The predicted class is the one with
        // largest population.
        NDManager manager = NDManager.newBaseManager();

        int [] per_cls_data = new int[n_classes_];
        for(int i = 0; i < n_classes_; i++) {
            per_cls_data[i] = (int)(y.eq(i).sum().toLongArray()[0]);
        }
        NDArray num_samples_per_class = manager.create(per_cls_data).toType(DataType.INT32, false);
        NDArray predicted_class = num_samples_per_class.argMax();
        Node node = new Node(
                _gini(y),
                (int)(y.getShape().getShape()[0]),
                num_samples_per_class,
                predicted_class);

        // Split recursively until maximum depth is reached.
        if( depth < max_depth ) {
            ArrayList<String> res = _best_split(X, y);

            if( res != null ){
                int idx = Integer.parseInt(res.get(0));
                double thr = Double.parseDouble(res.get(1));

                NDArray indices_left = X.get(":," + idx).lt( thr );
                NDArray X_left = X.get(indices_left);
                NDArray y_left = y.get(indices_left);

                NDArray indices_right = X.get(":," + idx).gte( thr );
                NDArray X_right = X.get(indices_right);
                NDArray y_right = y.get(indices_right);
                node.feature_index = idx;
                node.threshold = thr;
                node.left = _grow_tree(X_left, y_left, depth + 1);
                node.right = _grow_tree(X_right, y_right, depth + 1);
            }
        }
        return node;
    }

    public int [] predict(NDArray X) {
        int num_rows = (int)(X.getShape().getShape()[0]);
        int [] predictedCls = new int[num_rows];

        for(int i = 0; i < num_rows; i++)
            predictedCls[i] = _predict(X.get(i));

        return predictedCls;
    }

    // Predict class for a single sample.
    public int _predict(NDArray inputs) {
        Node node = tree_;
        while (node.left != null) {
            if( inputs.toDoubleArray()[node.feature_index] < node.threshold )
                node = node.left;
            else
                node = node.right;
        }
        return node.predicted_class.toType(DataType.INT32, false).toIntArray()[0];
    }
}
public class DecisionTree {

    public ArrayList<NDArray> load_breast_cancer(String fName) {
        ArrayList<String> contents = new ArrayList<>();
        int ncol = 0;
        try {
            File fr = new File(fName);
            BufferedReader in = null;

            in = new BufferedReader( new InputStreamReader(new FileInputStream(fr)));
            String line = in.readLine();  // skip column name line
            String[] curLine = line.strip().split(",");
            ncol = curLine.length;
            while( (line = in.readLine()) != null) {
                //System.out.println(line);
                contents.add(line.strip());
            }
            in.close();
        } catch(Exception e) {
            e.printStackTrace();
        }

        double [][] Xd = new double[contents.size()][ncol - 2];
        int [][]  Yd  = new int[contents.size()][1];

        for( int j = 0; j < contents.size(); j++ ) {
            if (contents.get(j).length() < 1)
                continue;
            String[] curLine = contents.get(j).strip().split(",");
            // skip
            for(int i = 2; i < curLine.length; i++) {
                Xd[j][i-2] = Double.parseDouble(curLine[i]);
            }
            if( curLine[1].equalsIgnoreCase("M") )
                Yd[j][0] = 0;
            else
                Yd[j][0] = 1;
        }
        NDManager manager = NDManager.newBaseManager();
        ArrayList<NDArray> xy = new ArrayList<>();
        xy.add(manager.create(Xd).toType(DataType.FLOAT64, false));
        xy.add(manager.create(Yd).toType(DataType.INT32, false));
        return xy;
    }

    public static void main(String[] args) {
        NDManager manager = NDManager.newBaseManager();
        DecisionTree DT = new DecisionTree();

        String fName = "./data/ML/breast_cancer.csv";
        ArrayList<NDArray> xy  = DT.load_breast_cancer(fName);
        NDArray X = xy.get(0), y = xy.get(1);
        System.out.println(X.getShape().toString());
        System.out.println(y.getShape().toString());

        ArrayList<NDArray> res = train_test_split(X, y, 0.2);
        NDArray Xtrain = res.get(0), Ytrain=res.get(1), Xtest = res.get(2), Ytest=res.get(3);
        System.out.println("Xtrain: " + Xtrain);
        System.out.println("Ytrain: " + Ytrain);
        System.out.println("Xtest: " + Xtest);
        System.out.println("Ytest: " + Ytest);

        DecisionTree_CART classifier = new DecisionTree_CART(5);
        classifier.fit(Xtrain, Ytrain);
        int [] y_predict = classifier.predict(Xtest);
        //Arrays.stream(y_predict).forEach(System.out::println);

        NDArray pred = manager.create(y_predict).toType(DataType.INT32, false);
        Ytest = Ytest.flatten();
        System.out.println("pred: " + Arrays.toString(pred.getShape().getShape()));
        System.out.println("Ytest: " + Arrays.toString(Ytest.getShape().getShape()));
        double acc = 1.0*((pred.eq(Ytest)).sum().toLongArray()[0])/y_predict.length;

        System.out.printf("Accuracy: %.4f\n", acc);
        System.exit(0);
    }


}
